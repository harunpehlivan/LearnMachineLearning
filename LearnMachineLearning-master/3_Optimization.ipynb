{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3.Optimization.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNW8LYU9WY7F7nadsmFArPX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KhanradCoder/LearnMachineLearning/blob/master/3_Optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIM_qwX5GRpx",
        "colab_type": "text"
      },
      "source": [
        "#Preprocessing the Data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUIsXzgMEXBJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "dataset = pd.read_csv('cancer.csv')\n",
        "x = dataset.iloc[:, 2:29].values\n",
        "y = dataset.iloc[:, 1].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZJD7JGDEpN_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7o6U-9vDEtBW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "x_test = scaler.transform(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biqmqbmeBGVB",
        "colab_type": "text"
      },
      "source": [
        "# Principle Component Analysis\n",
        "In PCA, we take two variables that are correlated and turn them into a vector, reducing the dimensions of our dataset.\n",
        "\n",
        "<img src=\"https://liorpachter.files.wordpress.com/2014/05/pca_figure1.jpg\" height=400 width=450>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tjHSQMjV2oB",
        "colab_type": "code",
        "outputId": "02d56240-e35e-4d3f-fd45-e27762dd2c78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components = 1)\n",
        "\n",
        "x_train_scaled = pca.fit_transform(x_train)\n",
        "print(x_train_scaled[:10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 3.10862742]\n",
            " [ 6.99512104]\n",
            " [13.39919721]\n",
            " [ 3.39219269]\n",
            " [-2.11751306]\n",
            " [-4.10203571]\n",
            " [12.99880763]\n",
            " [-0.55358029]\n",
            " [-4.83234678]\n",
            " [ 4.39581291]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dJpc3rKH75E",
        "colab_type": "text"
      },
      "source": [
        "You can see here if we reduce the data to one dimension we can plot it and perform logistic regression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLsj67_QE8UQ",
        "colab_type": "code",
        "outputId": "6e77a2d2-1922-433f-810d-b626de612d6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(x_train_scaled, y_train)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypnFwPQdB6aZ",
        "colab_type": "text"
      },
      "source": [
        "# Gradient Boosting\n",
        "\n",
        "Gradient boosing is one of the most powerful machine learning algorithms. Essentially, the model creates a bunch of weak models and takes the best components of each one using gradient descent. Think of this like random forrest but instead of just averaging all the values, the model picks the best branches of each tree."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_O4IN-rSGJFs",
        "colab_type": "code",
        "outputId": "52d3ab9e-0f64-4826-9098-106e68b697cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "gradientboost = GradientBoostingClassifier()\n",
        "gradientboost.fit(x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
              "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
              "                           max_features=None, max_leaf_nodes=None,\n",
              "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                           min_samples_leaf=1, min_samples_split=2,\n",
              "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                           n_iter_no_change=None, presort='deprecated',\n",
              "                           random_state=None, subsample=1.0, tol=0.0001,\n",
              "                           validation_fraction=0.1, verbose=0,\n",
              "                           warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwLYlm7dKAGO",
        "colab_type": "code",
        "outputId": "b47a802a-c3ac-4da2-8a27-45dee7bdfa65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "y_preds = gradientboost.predict(x_test)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(y_test, y_preds))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[66  2]\n",
            " [ 3 43]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdaB0qnyV5Bj",
        "colab_type": "text"
      },
      "source": [
        "##XGBoost\n",
        "The most popular and robust gradient boosting algorithm is XGBoost. This algorithm wins the most kaggle competitions and works well in a variety of scenarios, though it is prone to overfit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cFojDteI8mv",
        "colab_type": "code",
        "outputId": "b6f6efa3-e4d8-4121-aca0-0a5a3e7b2ef4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgboost = XGBClassifier()\n",
        "xgboost.fit(x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TFXidzrJB9w",
        "colab_type": "code",
        "outputId": "5c09ec71-1544-47da-e7c4-b2877f3cb82e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "y_preds = xgboost.predict(x_test)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(y_test, y_preds))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[66  2]\n",
            " [ 3 43]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpgS6INIKsWi",
        "colab_type": "text"
      },
      "source": [
        "**And just like that, you've completed this course. Check the github for links on what to do next. Have a great day and happy coding!**"
      ]
    }
  ]
}